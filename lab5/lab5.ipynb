{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c347bac",
   "metadata": {},
   "source": [
    "<h3>Morphosyntactic tagging</h3>\n",
    "<p>Konrad Przewłoka</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d751e043",
   "metadata": {},
   "source": [
    "<h4>Necessary imports</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bd8f9cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import requests\n",
    "import math\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44618f52",
   "metadata": {},
   "source": [
    "<h4>Load data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcb6b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "files = os.listdir(\"../ustawy\")\n",
    "for file in files:\n",
    "    with open(\"../ustawy\" + '/' + file, 'r', encoding='utf8') as f:\n",
    "        tmp = f.read().lower()\n",
    "        data.append(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f092dd6",
   "metadata": {},
   "source": [
    "<h4>Tagowanie i lematyzacja</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eecb228",
   "metadata": {},
   "outputs": [],
   "source": [
    "taged_data = [(lambda text: requests.post(\"http://localhost:9200\", data=text.encode(\"utf-8\")).content.decode(\"utf-8\"))(text) for text in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bddc3bf",
   "metadata": {},
   "source": [
    "<h4>Bigram computation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fa852248",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data=[]\n",
    "for file in taged_data:\n",
    "    lines = file.split(\"\\n\")\n",
    "    splits = [line.strip().split('\\t') for line in lines if line.startswith(\"\\t\")]\n",
    "    tokens = [(split[0].lower(),split[1].split(\":\")[0]) for split in splits if len(split)>=2]\n",
    "    tokenized_data.append(tokens)\n",
    "\n",
    "bigrams = [] \n",
    "for file in tokenized_data:\n",
    "    prev_token = None\n",
    "    file_bigrams=[]\n",
    "    for token in file:\n",
    "        if prev_token!=None:\n",
    "            file_bigrams.append((prev_token,token))\n",
    "        prev_token=token\n",
    "    bigrams.append(file_bigrams)\n",
    "tokens_total=[]    \n",
    "for file in tokenized_data:\n",
    "    for token in file:\n",
    "        if token[0].isalpha():\n",
    "            tokens_total.append(token)\n",
    "\n",
    "tokens_counter= collections.Counter(tokens_total)\n",
    "bigram_counter= collections.Counter([element for sublist in bigrams for element in sublist])\n",
    "\n",
    "tmp = []\n",
    "for key in bigram_counter.keys():\n",
    "    if not key[0][0].isalpha() or not key[1][0].isalpha():\n",
    "        tmp.append(key)\n",
    "        \n",
    "for key in tmp:\n",
    "    del bigram_counter[key]\n",
    "\n",
    "tokens_total = sum(tokens_counter.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec73e70c",
   "metadata": {},
   "source": [
    "<h4>LLR for bigrams</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "30c56b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('w', 'prep'), ('oczyszczal', 'subst')), 1557988.463414508),\n",
       " ((('w', 'prep'), ('nieszczelny', 'adj')), 1557988.463414508),\n",
       " ((('w', 'prep'), ('jedność', 'subst')), 1557988.463414508),\n",
       " ((('w', 'prep'), ('spisywać', 'ppas')), 1557988.463414508),\n",
       " ((('w', 'prep'), ('rio', 'subst')), 1557988.463414508),\n",
       " ((('w', 'prep'), ('dwuosobowy', 'adj')), 1557988.463414508),\n",
       " ((('w', 'prep'), ('dyskusja', 'subst')), 1557988.463414508),\n",
       " ((('w', 'prep'), ('czterobrygadowej', 'adj')), 1557988.463414508),\n",
       " ((('w', 'prep'), ('wyścigi', 'subst')), 1557988.463414508),\n",
       " ((('w', 'prep'), ('kontrakty', 'subst')), 1557988.463414508)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def h(ks):\n",
    "    total = float(sum(ks))\n",
    "    return sum([k/total * math.log(k / total + (k==0)) for k in ks])\n",
    "\n",
    "def llr(bigram):\n",
    "    k11= bigram_counter[bigram]\n",
    "    k12= tokens_counter[bigram[1]]-bigram_counter[bigram]\n",
    "    k21= tokens_counter[bigram[0]]-bigram_counter[bigram]\n",
    "    k22= tokens_total-k11-k12-k21\n",
    "    return 2*sum([k11,k12,k21,k22])*(h([k11+k12,k21+k22])-h([k11+k21,k12+k22]))\n",
    "\n",
    "bigrams_llr={bigram: llr(bigram) for bigram  in bigram_counter.keys()}\n",
    "collections.Counter(bigrams_llr).most_common()[:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78c8fb0",
   "metadata": {},
   "source": [
    "<h4>Syntactic categories split of bigrams</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d9f33ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('subst', 'subst'), 47863),\n",
       " (('subst', 'adj'), 27133),\n",
       " (('adj', 'subst'), 26138),\n",
       " (('subst', 'fin'), 16138),\n",
       " (('ger', 'subst'), 15579),\n",
       " (('prep', 'subst'), 12282),\n",
       " (('subst', 'prep'), 11349),\n",
       " (('subst', 'ppas'), 10699),\n",
       " (('fin', 'subst'), 8806),\n",
       " (('adj', 'fin'), 8695)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits={}\n",
    "tmp_count=[]\n",
    "for bigram, count in bigram_counter.items():\n",
    "    tmp_count.append((bigram[0][1],bigram[1][1]))\n",
    "    if not (bigram[0][1],bigram[1][1]) in splits:\n",
    "        splits[(bigram[0][1],bigram[1][1])]=[(bigram,count)]\n",
    "    else:\n",
    "        splits[(bigram[0][1],bigram[1][1])].append((bigram,count))\n",
    "    \n",
    "\n",
    "    \n",
    "top_splits = collections.Counter(tmp_count).most_common()[:10]\n",
    "top_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfdf941",
   "metadata": {},
   "source": [
    "<h4>Top 5 LLR bigrams for 10 largests splits</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "58a82b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: ('subst', 'subst')\n",
      "(('dzień', 'subst'), ('immatrykulacja', 'subst')) LLR:326336.9651891766\n",
      "(('dzień', 'subst'), ('pięćdziesiątnica', 'subst')) LLR:326336.9651891766\n",
      "(('dzień', 'subst'), ('upra', 'subst')) LLR:326336.9651891766\n",
      "(('dzień', 'subst'), ('dora', 'subst')) LLR:326336.9651891766\n",
      "(('dzień', 'subst'), ('opróż', 'subst')) LLR:326336.9651891766\n",
      "Split: ('subst', 'adj')\n",
      "(('dzień', 'subst'), ('powszedni', 'adj')) LLR:326336.9651891766\n",
      "(('dzień', 'subst'), ('zdjęciowy', 'adj')) LLR:326307.5545230917\n",
      "(('dzień', 'subst'), ('samowolny', 'adj')) LLR:326171.1084107933\n",
      "(('dzień', 'subst'), ('świąteczny', 'adj')) LLR:326144.9534819157\n",
      "(('dzień', 'subst'), ('siódmy', 'adj')) LLR:325725.5110191203\n",
      "Split: ('adj', 'subst')\n",
      "(('który', 'adj'), ('rych', 'subst')) LLR:521164.20924725314\n",
      "(('który', 'adj'), ('ustalania', 'subst')) LLR:521164.20924725314\n",
      "(('który', 'adj'), ('wygrany', 'subst')) LLR:521164.20924725314\n",
      "(('który', 'adj'), ('ustąpienie', 'subst')) LLR:521164.20924725314\n",
      "(('który', 'adj'), ('alfa', 'subst')) LLR:521164.20924725314\n",
      "Split: ('subst', 'fin')\n",
      "(('dzień', 'subst'), ('zrzekać', 'fin')) LLR:326279.1903538526\n",
      "(('dzień', 'subst'), ('brakować', 'fin')) LLR:326119.0492087414\n",
      "(('dzień', 'subst'), ('przejąć', 'fin')) LLR:325845.3127342396\n",
      "(('dzień', 'subst'), ('zaokrąglać', 'fin')) LLR:325491.60920320667\n",
      "(('dzień', 'subst'), ('przewyższać', 'fin')) LLR:325399.75970734213\n",
      "Split: ('ger', 'subst')\n",
      "(('wykonywać', 'ger'), ('odkuwka', 'subst')) LLR:72842.91307131822\n",
      "(('wykonywać', 'ger'), ('klosz', 'subst')) LLR:72842.91307131822\n",
      "(('wykonywać', 'ger'), ('deskowanie', 'subst')) LLR:72842.91307131822\n",
      "(('wykonywać', 'ger'), ('czopuch', 'subst')) LLR:72842.91307131822\n",
      "(('wykonywać', 'ger'), ('niwelacja', 'subst')) LLR:72842.91307131822\n",
      "Split: ('prep', 'subst')\n",
      "(('w', 'prep'), ('oczyszczal', 'subst')) LLR:1557988.463414508\n",
      "(('w', 'prep'), ('jedność', 'subst')) LLR:1557988.463414508\n",
      "(('w', 'prep'), ('rio', 'subst')) LLR:1557988.463414508\n",
      "(('w', 'prep'), ('dyskusja', 'subst')) LLR:1557988.463414508\n",
      "(('w', 'prep'), ('wyścigi', 'subst')) LLR:1557988.463414508\n",
      "Split: ('subst', 'prep')\n",
      "(('mowa', 'subst'), ('pod', 'prep')) LLR:303536.6376776911\n",
      "(('dzień', 'subst'), ('według', 'prep')) LLR:298917.9273174798\n",
      "(('ustawa', 'subst'), ('wśród', 'prep')) LLR:296682.3375086882\n",
      "(('mowa', 'subst'), ('bez', 'prep')) LLR:295434.18135773746\n",
      "(('dzień', 'subst'), ('pod', 'prep')) LLR:294665.9623479529\n",
      "Split: ('subst', 'ppas')\n",
      "(('dzień', 'subst'), ('rozpoznać', 'ppas')) LLR:325797.1228234022\n",
      "(('dzień', 'subst'), ('przepracować', 'ppas')) LLR:325354.1483417841\n",
      "(('dzień', 'subst'), ('określać', 'ppas')) LLR:324841.7582612358\n",
      "(('dzień', 'subst'), ('skrócić', 'ppas')) LLR:324092.8426017229\n",
      "(('dzień', 'subst'), ('usprawiedliwić', 'ppas')) LLR:323635.55991020583\n",
      "Split: ('fin', 'subst')\n",
      "(('być', 'fin'), ('nieza', 'subst')) LLR:240987.83037066433\n",
      "(('być', 'fin'), ('współkontrolowana', 'subst')) LLR:240987.83037066433\n",
      "(('być', 'fin'), ('rozpusz', 'subst')) LLR:240987.83037066433\n",
      "(('być', 'fin'), ('obo', 'subst')) LLR:240987.83037066433\n",
      "(('być', 'fin'), ('pęk', 'subst')) LLR:240958.41970457946\n",
      "Split: ('adj', 'fin')\n",
      "(('który', 'adj'), ('przeć', 'fin')) LLR:521164.20924725314\n",
      "(('który', 'adj'), ('uprawomocnić', 'fin')) LLR:521164.20924725314\n",
      "(('który', 'adj'), ('uchybić', 'fin')) LLR:521164.20924725314\n",
      "(('który', 'adj'), ('wykluczyć', 'fin')) LLR:521164.20924725314\n",
      "(('który', 'adj'), ('odczuwać', 'fin')) LLR:521164.20924725314\n"
     ]
    }
   ],
   "source": [
    "top_five={}\n",
    "random_five={}\n",
    "for split in top_splits:\n",
    "    top_five_llr[split[0]]=collections.Counter({bigram:bigrams_llr[bigram] for bigram,count in splits[split[0]]}).most_common()[:5]\n",
    "for split in top_splits:\n",
    "    print(\"Split: \"+str(split[0]))\n",
    "    for bigram,llr in top_five_llr[split[0]]:\n",
    "        print(str(bigram)+\" LLR:\"+str(llr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6bdd40",
   "metadata": {},
   "source": [
    "<h4>Answers</h4>\n",
    "<h5>I</h5>\n",
    "<p>Most common found pairs of words are of type noun and noun, noun and ajective, djective and noun. Almost all of the top 10 splits contain one noun per pair.</p>\n",
    "<h5>II</h5>\n",
    "<p>In my opininon the most useful bigrams seem to be parts of the ('subst', 'adj') and the ('subst', 'subst') partitions as the seem to descibe entities such as certain specific dates (ex. \"dzień pięćdziesiątnicy\")</p>\n",
    "<h5>III</h5>\n",
    "<p>I think that only a combination of both LLR and syntactic category can provide useful and genuine multiword expressions.</p>\n",
    "<h5>IV</h5>\n",
    "<p>Morphosyntactic categorization can be usefule when trying to recognize names of entities in texts and in Co-reference Resolution</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d707e0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
