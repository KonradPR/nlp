{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f0e4b8",
   "metadata": {},
   "source": [
    "<h3>Multiword expressions identification and extraction</h3>\n",
    "<p>Konrad Przewłoka</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0060489f",
   "metadata": {},
   "source": [
    "<h4>Necessary imports</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1bd93b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting prettytable\n",
      "  Downloading prettytable-3.5.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\kpr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from prettytable) (0.2.5)\n",
      "Installing collected packages: prettytable\n",
      "Successfully installed prettytable-3.5.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install prettytable\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.pl import Polish\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52220ef",
   "metadata": {},
   "source": [
    "<h4>Load data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25e6ef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "files = os.listdir(\"../ustawy\")\n",
    "for file in files:\n",
    "    with open(\"../ustawy\" + '/' + file, 'r', encoding='utf8') as f:\n",
    "        tmp = f.read().lower()\n",
    "        data.append(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a757ba",
   "metadata": {},
   "source": [
    "<h4>SpaCy tokenization</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a74002",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = Polish()\n",
    "tokenizer = nlp.tokenizer\n",
    "tokenized_data = [[t.text for t in tokenizer(r)] for r in data ]\n",
    "tokens_counter = collections.Counter([element for sublist in tokenized_data for element in sublist])\n",
    "tmp = []\n",
    "for key in tokens_counter.keys():\n",
    "    if not key.isalpha():\n",
    "        tmp.append(key)\n",
    "        \n",
    "for key in tmp:\n",
    "    del tokens_counter[key]\n",
    "    \n",
    "tokens_total = sum(tokens_counter.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6b92ff",
   "metadata": {},
   "source": [
    "<h4>Bigram computation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21c1795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams=[]\n",
    "for file in tokenized_data:\n",
    "    previous_token = None\n",
    "    for token in file:\n",
    "        if previous_token != None:\n",
    "            bigrams.append(\" \".join([previous_token,token]))\n",
    "        previous_token = token\n",
    "bigrams = collections.Counter(bigrams)\n",
    "\n",
    "#Filter out bigrams containing characters other than letters\n",
    "def is_correct(s):\n",
    "    if len(s.split())!=2:\n",
    "        return False\n",
    "    for element in s:\n",
    "        if not element.isalpha() and element!=' ':\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "tmp = []\n",
    "for key in bigrams.keys():\n",
    "    if not is_correct(key):\n",
    "        tmp.append(key)\n",
    "        \n",
    "for key in tmp:\n",
    "    del bigrams[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdaf205",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "<h4>Pointwise mutual inforamtion for bigrams</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9dceda67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kołowe jednoosiowe', 15.454037668330464),\n",
       " ('zbrojeń żelbeto', 15.454037668330464),\n",
       " ('prefabrykatów wnętrzowe', 15.454037668330464),\n",
       " ('gołe aluminiowe', 15.454037668330464),\n",
       " ('polistyrenu spienionego', 15.454037668330464),\n",
       " ('objaśnieniem figur', 15.454037668330464),\n",
       " ('wkładzie wnoszonym', 15.454037668330464),\n",
       " ('doktorem habilitowanym', 15.454037668330464),\n",
       " ('losy loteryjne', 15.454037668330464),\n",
       " ('ugaszone zapałki', 15.454037668330464)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_total= sum(bigrams.values())\n",
    "def pmi(bigram):\n",
    "    p_w1 = tokens_counter[bigram.split()[0]]/tokens_total\n",
    "    p_w2 = tokens_counter[bigram.split()[1]]/tokens_total\n",
    "    p_bigram = bigrams[bigram]/bigrams_total\n",
    "    return math.log(p_bigram/(p_w1*p_w2))\n",
    "bigrams_pmi = {bigram: pmi(bigram) for bigram  in bigrams.keys()}\n",
    "collections.Counter(bigrams_pmi).most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1c3ffc",
   "metadata": {},
   "source": [
    "<h4>Pointwise mutual inforamtion for filtered bigrams</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99d4dbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('świeckie przygotowujące', 14.136205671251723),\n",
       " ('klęskami żywiołowymi', 14.136205671251723),\n",
       " ('ręcznego miotacza', 14.136205671251723),\n",
       " ('stajnią wyścigową', 14.136205671251723),\n",
       " ('otworami wiertniczymi', 14.136205671251723),\n",
       " ('obcowania płciowego', 14.136205671251723),\n",
       " ('młyny kulowe', 14.136205671251723),\n",
       " ('młynki młotkowe', 14.136205671251723),\n",
       " ('zaszkodzić wynikom', 14.136205671251723),\n",
       " ('grzegorz schetyna', 14.136205671251723)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filltered_bigrams = {bigram: count for bigram, count  in bigrams.items() if count>=5} \n",
    "def pmi(bigram):\n",
    "    p_w1 = tokens_counter[bigram.split()[0]]/tokens_total\n",
    "    p_w2 = tokens_counter[bigram.split()[1]]/tokens_total\n",
    "    p_bigram = filltered_bigrams[bigram]/sum(filltered_bigrams.values())\n",
    "    return math.log(p_bigram/(p_w1*p_w2))\n",
    "filltered_bigrams_pmi = {bigram: pmi(bigram) for bigram  in filltered_bigrams.keys()}\n",
    "collections.Counter(filltered_bigrams_pmi).most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e273d12",
   "metadata": {},
   "source": [
    "<h4>LLR for bigrams</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a31063b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w alfabecie', 1547749.5438785334),\n",
       " ('w oczyszczal', 1547749.5438785334),\n",
       " ('w opisach', 1547749.5438785334),\n",
       " ('w figurach', 1547749.5438785334),\n",
       " ('w uczciwych', 1547749.5438785334),\n",
       " ('w niewielkim', 1547749.5438785334),\n",
       " ('w tłumaczeniach', 1547749.5438785334),\n",
       " ('w koronie', 1547749.5438785334),\n",
       " ('w uchylonym', 1547749.5438785334),\n",
       " ('w niezmniejszonym', 1547749.5438785334)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def h(ks):\n",
    "    total = float(sum(ks))\n",
    "    return sum([k/total * math.log(k / total + (k==0)) for k in ks])\n",
    "\n",
    "def llr(bigram):\n",
    "    k11= bigrams[bigram]\n",
    "    k12= tokens_counter[bigram.split()[1]]-bigrams[bigram]\n",
    "    k21= tokens_counter[bigram.split()[0]]-bigrams[bigram]\n",
    "    k22= tokens_total-k11-k12-k21\n",
    "    return 2*sum([k11,k12,k21,k22])*(h([k11+k12,k21+k22])-h([k11+k21,k12+k22]))\n",
    "\n",
    "bigrams_llr={bigram: llr(bigram) for bigram  in bigrams.keys()}\n",
    "collections.Counter(bigrams_llr).most_common()[:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b39b7c7",
   "metadata": {},
   "source": [
    "<h4>Trigram computation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "366910aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams=[]\n",
    "for file in tokenized_data:\n",
    "    previous_token = None\n",
    "    previous_previous_token = None\n",
    "    for token in file:\n",
    "        if previous_token != None and previous_previous_token!=None:\n",
    "            trigrams.append(\" \".join([previous_previous_token,previous_token,token]))\n",
    "        previous_previous_token = previous_token\n",
    "        previous_token = token\n",
    "trigrams = collections.Counter(trigrams)\n",
    "\n",
    "def is_correct(s):\n",
    "    if len(s.split())!=3:\n",
    "        return False\n",
    "    for element in s:\n",
    "        if not element.isalpha() and element!=' ':\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "tmp = []\n",
    "for key in trigrams.keys():\n",
    "    if not is_correct(key):\n",
    "        tmp.append(key)\n",
    "        \n",
    "for key in tmp:\n",
    "    del trigrams[key]\n",
    "    \n",
    "filltered_trigrams = {trigram: count for trigram, count  in trigrams.items() if count>=5} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232f702d",
   "metadata": {},
   "source": [
    "<h4>Pointwise mutual inforamtion for filltered trigrams</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6691c8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('profilem zaufanym epuap', 25.622883236510766),\n",
       " ('finałowego turnieju mistrzostw', 25.359154405081476),\n",
       " ('przedwczesnego wyrębu drzewostanu', 25.23885705045838),\n",
       " ('potwierdzonym profilem zaufanym', 25.15638223781623),\n",
       " ('piłce nożnej uefa', 25.115796957701154),\n",
       " ('cienką sierścią zwierzęcą', 24.873883303704954),\n",
       " ('szybkiemu postępowi technicznemu', 24.828937592000834),\n",
       " ('turnieju mistrzostw europy', 24.828526154019308),\n",
       " ('grożącą jemu samemu', 24.661541685423558),\n",
       " ('wypalonym paliwem jądrowym', 24.610248391036006)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_filltered_trigrams=sum(filltered_bigrams.values())\n",
    "def pmi(trigram):\n",
    "    p_w1 = tokens_counter[trigram.split()[0]]/tokens_total\n",
    "    p_w2 = tokens_counter[trigram.split()[1]]/tokens_total\n",
    "    p_w3 = tokens_counter[trigram.split()[2]]/tokens_total\n",
    "    p_trigram = filltered_trigrams[trigram]/total_filltered_trigrams\n",
    "    return math.log(p_trigram/(p_w1*p_w2*p_w3))\n",
    "filltered_trigrams_pmi = {trigram: pmi(trigram) for trigram  in filltered_trigrams.keys()}\n",
    "collections.Counter(filltered_trigrams_pmi).most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd845313",
   "metadata": {},
   "source": [
    "<h4>LLR for trigrams</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "977a56f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mowa w powyższej', 323790.16559965984),\n",
       " ('mowa w przywołanym', 323790.16559965984),\n",
       " ('mowa w europejskiej', 323732.40855133283),\n",
       " ('mowa w sekcji', 323732.40855133283),\n",
       " ('mowa w paragrafach', 323704.73287230177),\n",
       " ('mowa w artykułach', 323677.562536909),\n",
       " ('mowa w artykule', 323650.79491234885),\n",
       " ('mowa w przepisie', 323650.79491234885),\n",
       " ('mowa w dyrektywie', 323624.36218229897),\n",
       " ('mowa w rozdziałach', 323572.32076727395)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def h(ks):\n",
    "    total = float(sum(ks))\n",
    "    return sum([k/total * math.log(k / total + (k==0)) for k in ks])\n",
    "\n",
    "def llr(trigram):\n",
    "    k11= trigrams[trigram]\n",
    "    k12= bigrams[\" \".join([trigram.split()[1],trigram.split()[2]])]-trigrams[trigram]\n",
    "    k21= bigrams[\" \".join([trigram.split()[0],trigram.split()[1]])]-trigrams[trigram]\n",
    "    k22= tokens_total-k11-k12-k21\n",
    "    return 2*sum([k11,k12,k21,k22])*(h([k11+k12,k21+k22])-h([k11+k21,k12+k22]))\n",
    "\n",
    "trigrams_llr={trigram: llr(trigram) for trigram  in trigrams.keys()}\n",
    "collections.Counter(trigrams_llr).most_common()[:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a1772",
   "metadata": {},
   "source": [
    "<h4>Bigram table</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bec3deea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+-------------------------------------------+\n",
      "|                       PMI                       |                    LLR                    |\n",
      "+-------------------------------------------------+-------------------------------------------+\n",
      "| ('świeckie przygotowujące', 14.136205671251723) |    ('w alfabecie', 1547749.5438785334)    |\n",
      "|   ('klęskami żywiołowymi', 14.136205671251723)  |    ('w oczyszczal', 1547749.5438785334)   |\n",
      "|    ('ręcznego miotacza', 14.136205671251723)    |     ('w opisach', 1547749.5438785334)     |\n",
      "|    ('stajnią wyścigową', 14.136205671251723)    |     ('w figurach', 1547749.5438785334)    |\n",
      "|  ('otworami wiertniczymi', 14.136205671251723)  |    ('w uczciwych', 1547749.5438785334)    |\n",
      "|   ('obcowania płciowego', 14.136205671251723)   |    ('w niewielkim', 1547749.5438785334)   |\n",
      "|       ('młyny kulowe', 14.136205671251723)      |  ('w tłumaczeniach', 1547749.5438785334)  |\n",
      "|     ('młynki młotkowe', 14.136205671251723)     |     ('w koronie', 1547749.5438785334)     |\n",
      "|    ('zaszkodzić wynikom', 14.136205671251723)   |    ('w uchylonym', 1547749.5438785334)    |\n",
      "|    ('grzegorz schetyna', 14.136205671251723)    | ('w niezmniejszonym', 1547749.5438785334) |\n",
      "+-------------------------------------------------+-------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "t = PrettyTable(['PMI', 'LLR'])\n",
    "for i in range(10):\n",
    "    t.add_row([collections.Counter(filltered_bigrams_pmi).most_common()[i],collections.Counter(bigrams_llr).most_common()[i] ])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e298a187",
   "metadata": {},
   "source": [
    "<h4>Trigram table</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "32aff945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------+---------------------------------------------+\n",
      "|                           PMI                            |                     LLR                     |\n",
      "+----------------------------------------------------------+---------------------------------------------+\n",
      "|     ('profilem zaufanym epuap', 25.622883236510766)      |   ('mowa w powyższej', 323790.16559965984)  |\n",
      "|  ('finałowego turnieju mistrzostw', 25.359154405081476)  |  ('mowa w przywołanym', 323790.16559965984) |\n",
      "| ('przedwczesnego wyrębu drzewostanu', 25.23885705045838) | ('mowa w europejskiej', 323732.40855133283) |\n",
      "|  ('potwierdzonym profilem zaufanym', 25.15638223781623)  |    ('mowa w sekcji', 323732.40855133283)    |\n",
      "|        ('piłce nożnej uefa', 25.115796957701154)         |  ('mowa w paragrafach', 323704.73287230177) |\n",
      "|    ('cienką sierścią zwierzęcą', 24.873883303704954)     |   ('mowa w artykułach', 323677.562536909)   |\n",
      "| ('szybkiemu postępowi technicznemu', 24.828937592000834) |   ('mowa w artykule', 323650.79491234885)   |\n",
      "|    ('turnieju mistrzostw europy', 24.828526154019308)    |   ('mowa w przepisie', 323650.79491234885)  |\n",
      "|       ('grożącą jemu samemu', 24.661541685423558)        |  ('mowa w dyrektywie', 323624.36218229897)  |\n",
      "|    ('wypalonym paliwem jądrowym', 24.610248391036006)    |  ('mowa w rozdziałach', 323572.32076727395) |\n",
      "+----------------------------------------------------------+---------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "t = PrettyTable(['PMI', 'LLR'])\n",
    "for i in range(10):\n",
    "    t.add_row([collections.Counter(filltered_trigrams_pmi).most_common()[i],collections.Counter(trigrams_llr).most_common()[i] ])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3442cb68",
   "metadata": {},
   "source": [
    "<h4>Answers</h4>\n",
    "<h5>I</h5>\n",
    "<p>We have to filter bigrams rather than token sequences in order to preserve real and meaningful connections between tokens. For example if we have a sequence of tokens looking like this: a1 a2 n1 n2 a3 a4, where a&lt;nr&gt; represents a valid token and n&lt;nr&gt; represents an invalid token, if we filter tokens first we will get bigrams: a1a2 a2a3 a3a4 whereas if we first create bigrams and filter then we will get bigrams a1a2 a3a4. As we see the operation order is important as we can end up with different bigrams depending of the order of operations. Filtering after creating bigrams is preferred as it preserves original words collocations.</p>\n",
    "<h5>II</h5>\n",
    "<p>In my humble opinion PMI seems to be working better for trigrams since the expressions found look more significant in terms of information. Similarly, for bigrams PMI seems to also be the prefered method. It is hard to select between PMI with and without filtering, but I believe that PMI with filtering should be working better since filtering should reduce outliers.</p>\n",
    "<h5>III</h5>\n",
    "<p>Used methods may be used to discover different types of multiword expressions such as multiword named entities and multiword terms.</p>\n",
    "<h5>IV</h5>\n",
    "<p>It is definitely possible to devise better solutions especially for certain types of datasets. Depending on the task given and the understanding of the data it may be possible to devise better or additional filters other than non-letter characters. For example it may be a good idea to filter out expressions that are constructed from tokens that all represent the same part of speech (such as 'świeckie przygotowujące') since they are most likely parts of longer expressions and by themselves convey little information.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68f3afa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
