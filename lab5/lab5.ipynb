{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51884680",
   "metadata": {},
   "source": [
    "<h3>Language modelling</h3>\n",
    "<p>Konrad Przewłoka</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0c07f6",
   "metadata": {},
   "source": [
    "<h4>Imports</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "768663e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch\n",
    "#!pip install transformers\n",
    "#!pip install sacremoses\n",
    "from pprint import pprint\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b5d277",
   "metadata": {},
   "source": [
    "<h4>Loading Geotrend distillbert polish model<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "125ed0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_distilbert = transformers.AutoTokenizer.from_pretrained(\"Geotrend/distilbert-base-pl-cased\")\n",
    "model_distilbert = transformers.AutoModelForMaskedLM.from_pretrained(\"Geotrend/distilbert-base-pl-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7710aed7",
   "metadata": {},
   "source": [
    "<h4>Loading polish BERT uncased model<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8eefa873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dkleczek/bert-base-polish-uncased-v1 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer_bert_uncased = transformers.AutoTokenizer.from_pretrained(\"dkleczek/bert-base-polish-uncased-v1\")\n",
    "\n",
    "model_bert_uncased = transformers.AutoModelForMaskedLM.from_pretrained(\"dkleczek/bert-base-polish-uncased-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a457939",
   "metadata": {},
   "source": [
    "<h4>Loading polish BERT cased model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08d09739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dkleczek/bert-base-polish-cased-v1 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer_bert_cased = transformers.AutoTokenizer.from_pretrained(\"dkleczek/bert-base-polish-cased-v1\")\n",
    "\n",
    "model_bert_cased = transformers.AutoModelForMaskedLM.from_pretrained(\"dkleczek/bert-base-polish-cased-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa6c911",
   "metadata": {},
   "source": [
    "<h4>Utility array of models</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c39a332",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    {'name':\"Distilled BERT polish\", 'model':model_distilbert,'tokenizer':tokenizer_distilbert},\n",
    "    {'name':\"Polish BERT uncased\", 'model':model_bert_uncased,'tokenizer':tokenizer_bert_uncased},\n",
    "    {'name':\"Polish BERT cased\", 'model':model_bert_cased,'tokenizer':tokenizer_bert_cased}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d4c19a",
   "metadata": {},
   "source": [
    "<h4>Polish cases checking</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "52e5ccac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distilled BERT polish\n",
      "Warszawa to największe [MASK].\n",
      "Warszawa to największe miasto.\n",
      "Warszawa to największe miasta.\n",
      "Warszawa to największe Miasto.\n",
      "Marek bardzo długo szukał [MASK].\n",
      "Marek bardzo długo szukał gry.\n",
      "Marek bardzo długo szukał dzieci.\n",
      "Marek bardzo długo szukał ojca.\n",
      "Prezenty podobały się [MASK].\n",
      "Prezenty podobały się LGBT.\n",
      "Prezenty podobały się temat.\n",
      "Prezenty podobały się tzw.\n",
      "Po wejściu na dach można obejrzeć [MASK].\n",
      "Po wejściu na dach można obejrzeć ulice.\n",
      "Po wejściu na dach można obejrzeć miejsca.\n",
      "Po wejściu na dach można obejrzeć budynek.\n",
      "Tomasz postanowił pojechać do domu z [MASK].\n",
      "Tomasz postanowił pojechać do domu z rodziny.\n",
      "Tomasz postanowił pojechać do domu z domu.\n",
      "Tomasz postanowił pojechać do domu z Warszawy.\n",
      "Anna od dawna marzyła o [MASK].\n",
      "Anna od dawna marzyła o wojnie.\n",
      "Anna od dawna marzyła o romans.\n",
      "Anna od dawna marzyła o tron.\n",
      "Witaj [MASK]!\n",
      "Witaj !!\n",
      "Witaj ##sz!\n",
      "Witaj Jak!\n",
      "Polish BERT uncased\n",
      "Warszawa to największe [MASK].\n",
      "Warszawa to największe miasto.\n",
      "Warszawa to największe miejsce.\n",
      "Warszawa to największe lotnisko.\n",
      "Marek bardzo długo szukał [MASK].\n",
      "Marek bardzo długo szukał zemsty.\n",
      "Marek bardzo długo szukał pomocy.\n",
      "Marek bardzo długo szukał złota.\n",
      "Prezenty podobały się [MASK].\n",
      "Prezenty podobały się wszystkim.\n",
      "Prezenty podobały się mamie.\n",
      "Prezenty podobały się jej.\n",
      "Po wejściu na dach można obejrzeć [MASK].\n",
      "Po wejściu na dach można obejrzeć film.\n",
      "Po wejściu na dach można obejrzeć wszystko.\n",
      "Po wejściu na dach można obejrzeć schody.\n",
      "Tomasz postanowił pojechać do domu z [MASK].\n",
      "Tomasz postanowił pojechać do domu z rodzina.\n",
      "Tomasz postanowił pojechać do domu z zona.\n",
      "Tomasz postanowił pojechać do domu z rodzicami.\n",
      "Anna od dawna marzyła o [MASK].\n",
      "Anna od dawna marzyła o tobie.\n",
      "Anna od dawna marzyła o pokoju.\n",
      "Anna od dawna marzyła o rodzinie.\n",
      "Witaj [MASK]!\n",
      "Witaj kochanie!\n",
      "Witaj mamo!\n",
      "Witaj tato!\n",
      "Polish BERT cased\n",
      "Warszawa to największe [MASK].\n",
      "Warszawa to największe miasto.\n",
      "Warszawa to największe województwo.\n",
      "Warszawa to największe lotnisko.\n",
      "Marek bardzo długo szukał [MASK].\n",
      "Marek bardzo długo szukał pracy.\n",
      "Marek bardzo długo szukał pomocy.\n",
      "Marek bardzo długo szukał pieniędzy.\n",
      "Prezenty podobały się [MASK].\n",
      "Prezenty podobały się wszystkim.\n",
      "Prezenty podobały się każdemu.\n",
      "Prezenty podobały się publiczności.\n",
      "Po wejściu na dach można obejrzeć [MASK].\n",
      "Po wejściu na dach można obejrzeć film.\n",
      "Po wejściu na dach można obejrzeć wystawę.\n",
      "Po wejściu na dach można obejrzeć muzeum.\n",
      "Tomasz postanowił pojechać do domu z [MASK].\n",
      "Tomasz postanowił pojechać do domu z rodzicami.\n",
      "Tomasz postanowił pojechać do domu z dziećmi.\n",
      "Tomasz postanowił pojechać do domu z rodziną.\n",
      "Anna od dawna marzyła o [MASK].\n",
      "Anna od dawna marzyła o ślubie.\n",
      "Anna od dawna marzyła o małżeństwie.\n",
      "Anna od dawna marzyła o dziecku.\n",
      "Witaj [MASK]!\n",
      "Witaj kochanie!\n",
      "Witaj ponownie!\n",
      "Witaj tutaj!\n"
     ]
    }
   ],
   "source": [
    "def unmask_sentece(model,sentence,num_tokens):\n",
    "    sentence = sentence.replace('[MASK]',model['tokenizer'].mask_token)\n",
    "    inputs = model['tokenizer'](sentence, return_tensors=\"pt\")\n",
    "    mask_token_index = torch.where(inputs[\"input_ids\"] == model['tokenizer'].mask_token_id)[1]\n",
    "    token_logits = model['model'](**inputs).logits\n",
    "    mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "    top_tokens = torch.topk(mask_token_logits, num_tokens, dim=1).indices[0].tolist()\n",
    "    return top_tokens\n",
    "\n",
    "example_sentences=[\n",
    "    \"Warszawa to największe [MASK].\",\n",
    "    \"Marek bardzo długo szukał [MASK].\",\n",
    "    \"Prezenty podobały się [MASK].\",\n",
    "    \"Po wejściu na dach można obejrzeć [MASK].\",\n",
    "    \"Tomasz postanowił pojechać do domu z [MASK].\",\n",
    "    \"Anna od dawna marzyła o [MASK].\",\n",
    "    \"Witaj [MASK]!\"\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    print(model['name'])\n",
    "    for sentence in example_sentences:\n",
    "        print(sentence)\n",
    "        for token in unmask_sentece(model, sentence,3):\n",
    "            print(sentence.replace(model['tokenizer'].mask_token,model['tokenizer'].decode([token])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91c2613",
   "metadata": {},
   "source": [
    "<h4>Testing long-range relationships</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0d6d5369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distilled BERT polish\n",
      "Anna wybrała się do sklepu, gdzie [MASK] mleko.\n",
      "Anna wybrała się do sklepu, gdzie miała mleko.\n",
      "Anna wybrała się do sklepu, gdzie zdobyła mleko.\n",
      "Marek wrócił do domu i natychmiast [MASK] na kanapie.\n",
      "Marek wrócił do domu i natychmiast zmarł na kanapie.\n",
      "Marek wrócił do domu i natychmiast przeszedł na kanapie.\n",
      "To drzewo [MASK] 50 lat zanim spłonęło.\n",
      "To drzewo około 50 lat zanim spłonęło.\n",
      "To drzewo było 50 lat zanim spłonęło.\n",
      "Polish BERT uncased\n",
      "Anna wybrała się do sklepu, gdzie [MASK] mleko.\n",
      "Anna wybrała się do sklepu, gdzie kupuje mleko.\n",
      "Anna wybrała się do sklepu, gdzie pija mleko.\n",
      "Marek wrócił do domu i natychmiast [MASK] na kanapie.\n",
      "Marek wrócił do domu i natychmiast spał na kanapie.\n",
      "Marek wrócił do domu i natychmiast usiadł na kanapie.\n",
      "To drzewo [MASK] 50 lat zanim spłonęło.\n",
      "To drzewo miało 50 lat zanim spłonęło.\n",
      "To drzewo przetrwało 50 lat zanim spłonęło.\n",
      "Polish BERT cased\n",
      "Anna wybrała się do sklepu, gdzie [MASK] mleko.\n",
      "Anna wybrała się do sklepu, gdzie kupiła mleko.\n",
      "Anna wybrała się do sklepu, gdzie kupić mleko.\n",
      "Marek wrócił do domu i natychmiast [MASK] na kanapie.\n",
      "Marek wrócił do domu i natychmiast spał na kanapie.\n",
      "Marek wrócił do domu i natychmiast usiadł na kanapie.\n",
      "To drzewo [MASK] 50 lat zanim spłonęło.\n",
      "To drzewo miało 50 lat zanim spłonęło.\n",
      "To drzewo żyło 50 lat zanim spłonęło.\n"
     ]
    }
   ],
   "source": [
    "example_sentences_relationships=[\n",
    "    \"Anna wybrała się do sklepu, gdzie [MASK] mleko.\",\n",
    "    \"Marek wrócił do domu i natychmiast [MASK] na kanapie.\",\n",
    "    \"To drzewo [MASK] 50 lat zanim spłonęło.\"\n",
    "]\n",
    "for model in models:\n",
    "    print(model['name'])\n",
    "    for sentence in example_sentences_relationships:\n",
    "        print(sentence)\n",
    "        for token in unmask_sentece(model, sentence,2):\n",
    "            print(sentence.replace(model['tokenizer'].mask_token,model['tokenizer'].decode([token])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642601f3",
   "metadata": {},
   "source": [
    "<h4>Checking real-world knolwedge</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "61146e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distilled BERT polish\n",
      "[MASK] wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\n",
      "Na wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\n",
      "We wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\n",
      "Tomek studiuje polonistykę na [MASK].\n",
      "Tomek studiuje polonistykę na Uniwersytecie.\n",
      "Tomek studiuje polonistykę na polski.\n",
      "[MASK] wschodzi o ósmej i zachodzi około szesnastej.\n",
      "Od wschodzi o ósmej i zachodzi około szesnastej.\n",
      "Grupa wschodzi o ósmej i zachodzi około szesnastej.\n",
      "Polish BERT uncased\n",
      "[MASK] wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\n",
      "woda wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\n",
      "nie wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\n",
      "Tomek studiuje polonistykę na [MASK].\n",
      "Tomek studiuje polonistykę na uniwersytecie.\n",
      "Tomek studiuje polonistykę na harvardzie.\n",
      "[MASK] wschodzi o ósmej i zachodzi około szesnastej.\n",
      "i wschodzi o ósmej i zachodzi około szesnastej.\n",
      "kometa wschodzi o ósmej i zachodzi około szesnastej.\n",
      "Polish BERT cased\n",
      "[MASK] wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\n",
      "Woda wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\n",
      "Mięso wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\n",
      "Tomek studiuje polonistykę na [MASK].\n",
      "Tomek studiuje polonistykę na UW.\n",
      "Tomek studiuje polonistykę na UJ.\n",
      "[MASK] wschodzi o ósmej i zachodzi około szesnastej.\n",
      "Słońce wschodzi o ósmej i zachodzi około szesnastej.\n",
      "Księżyc wschodzi o ósmej i zachodzi około szesnastej.\n"
     ]
    }
   ],
   "source": [
    "example_sentences_relationships=[\n",
    "    \"[MASK] wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\",\n",
    "    \"Tomek studiuje polonistykę na [MASK].\",\n",
    "    \"[MASK] wschodzi o ósmej i zachodzi około szesnastej.\"\n",
    "]\n",
    "for model in models:\n",
    "    print(model['name'])\n",
    "    for sentence in example_sentences_relationships:\n",
    "        print(sentence)\n",
    "        for token in unmask_sentece(model, sentence,2):\n",
    "            print(sentence.replace(model['tokenizer'].mask_token,model['tokenizer'].decode([token])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e564f4",
   "metadata": {},
   "source": [
    "<h4>Answers</h4>\n",
    "<h5>I</h5>\n",
    "<p>The model to produce best results was Polish BERT cased, available at: https://huggingface.co/dkleczek/bert-base-polish-cased-v1</p>\n",
    "<h5>II</h5>\n",
    "<p>All of tested models seem to capture at least a rudimentary level of polish grammar</p>\n",
    "<h5>III</h5>\n",
    "<p>All models display capability in terms of capturing long-distance relationships. That being said, the distilled BERT model results are of lower quality compared to others. The polish BERT cased model seems to offer the best results in terms of capturing long-distance relationships.</p>\n",
    "<h5>IV</h5>\n",
    "<p>Both polish BERT cased and uncased were able to capture significant level of real-world knowledge while the distilled BERT model was rather unsuccessful in this regard.</p>\n",
    "<h5>V</h5>\n",
    "<p>The most striking mistakes:\n",
    "    <ul>\n",
    "   <li> Na wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\n",
    "   <li> We wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\n",
    "   <li> Witaj !!\n",
    "   <li> Witaj ##sz!\n",
    "   <li> Prezenty podobały się tzw.\n",
    "    </ul>\n",
    "   Worst mistakes were made by the distilled BERT model.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b867a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
